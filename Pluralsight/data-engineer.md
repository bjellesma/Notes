Data Engineers use a process called **Extract, Transform, Load (ETL)** to process data. Extract refers to scraping the data from another source. Transform refers to formatting the data to be usable and reliable. Load refers to putting the data into a database or data warehouse, on prem or in the cloud.

**Data Lakes** typically store the untransformed data as the idea is that employees can transform the data from a data lake themselves.

Below is a screenshot of the **data ecosystem** showing how the data engineer will perform the ETL operations to get the data ready for data warehousing where the data analysists and data scientists will then use the data. 

## Roles

**Data Engineers** are responsible for the setup of data pipelines and data storage solutions. They typically have skill in System architecture, python, sql, hadoop, spark, and kafka.

![image](https://github.com/bjellesma/Notes/assets/7660667/af426d20-8221-4a8f-a0da-2cbad4e776d9)


